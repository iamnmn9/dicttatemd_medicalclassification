{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGvxmIaEp2M-"
      },
      "source": [
        "##Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB9Oc5c65i7j",
        "outputId": "48f1ad54-3df1-41bd-bfb4-15d775f4796c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kVHgloY5p1oF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1fkE5lap55S"
      },
      "source": [
        "##Data Load and dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QcFYF0dfqIia"
      },
      "outputs": [],
      "source": [
        "csv_file_path = '/content/mtsamples.csv'\n",
        "df = pd.read_csv(csv_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyFBcB2Ip5Hf"
      },
      "source": [
        "##Data Cleaning and processing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "netYRNOoRRKA",
        "outputId": "ef8d5c21-223d-4483-dfde-add8a0c934cd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "oNTZzoHaqNX6"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset=['medical_specialty'], axis=0)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = text.split()\n",
        "    words = [word.lower() for word in words]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in string.punctuation and word not in stop_words]\n",
        "    processed_text = ' '.join(words)\n",
        "    return processed_text\n",
        "\n",
        "df['description'] = df['description'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPte_qbTqYE0"
      },
      "source": [
        "##Data split 80-20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HAswwu6lqb19"
      },
      "outputs": [],
      "source": [
        "X = df['description']\n",
        "y = df['medical_specialty']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZukEQQ7CqeKI"
      },
      "source": [
        "##Using pretrained Bert for classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mCfuLTaqiKe",
        "outputId": "7c398c41-b17c-46f9-f06f-ceeafe6a3780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(df['medical_specialty'].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we21G_CStTHK"
      },
      "source": [
        "##Tokenizing and creating labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Y2QFHSFVtVee"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 1024\n",
        "train_texts = X_train.tolist()\n",
        "test_texts = X_test.tolist()\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "\n",
        "\n",
        "train_labels = label_encoder.fit_transform(y_train)\n",
        "val_labels = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vESGgoINtWNH"
      },
      "source": [
        "##PyTorch data loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "gDjh6gwZtfX5"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels))\n",
        "val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], torch.tensor(val_labels))\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g5ONwzItitN"
      },
      "source": [
        "##Training params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ_65E8XtpWp",
        "outputId": "5680ff5f-0f14-40d4-fa02-8a4404ce38ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "learning_rate = 2e-5\n",
        "adam_epsilon = 1e-8\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK1shaExtp2F"
      },
      "source": [
        "#Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iN7DNm7tt8y",
        "outputId": "751f7ade-b300-4292-b049-f46decee0890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Average Training Loss: 3.028245277404785\n",
            "Epoch 2 - Average Training Loss: 2.5115823097229004\n",
            "Epoch 3 - Average Training Loss: 2.2120892362594606\n",
            "Epoch 4 - Average Training Loss: 1.996423505783081\n",
            "Epoch 5 - Average Training Loss: 1.8281959981918334\n",
            "Epoch 6 - Average Training Loss: 1.6948720455169677\n",
            "Epoch 7 - Average Training Loss: 1.5901589574813844\n",
            "Epoch 8 - Average Training Loss: 1.4918160123825073\n",
            "Epoch 9 - Average Training Loss: 1.4178487005233764\n",
            "Epoch 10 - Average Training Loss: 1.3614891738891601\n",
            "Epoch 11 - Average Training Loss: 1.2940166158676147\n",
            "Epoch 12 - Average Training Loss: 1.2430125331878663\n",
            "Epoch 13 - Average Training Loss: 1.2018304438591003\n",
            "Epoch 14 - Average Training Loss: 1.156374162197113\n",
            "Epoch 15 - Average Training Loss: 1.1214402017593383\n",
            "Epoch 16 - Average Training Loss: 1.0961581621170045\n",
            "Epoch 17 - Average Training Loss: 1.0617342200279236\n",
            "Epoch 18 - Average Training Loss: 1.0423839845657348\n",
            "Epoch 19 - Average Training Loss: 1.0161161584854126\n",
            "Epoch 20 - Average Training Loss: 1.0137461776733399\n",
            "Epoch 21 - Average Training Loss: 0.9841254363059998\n",
            "Epoch 22 - Average Training Loss: 0.9689224028587341\n",
            "Epoch 23 - Average Training Loss: 0.9449424104690551\n",
            "Epoch 24 - Average Training Loss: 0.9408805208206177\n",
            "Epoch 25 - Average Training Loss: 0.9233337612152099\n",
            "Epoch 26 - Average Training Loss: 0.9197991261482239\n",
            "Epoch 27 - Average Training Loss: 0.9100465388298035\n",
            "Epoch 28 - Average Training Loss: 0.8924323348999024\n",
            "Epoch 29 - Average Training Loss: 0.886493860244751\n",
            "Epoch 30 - Average Training Loss: 0.8805209732055664\n",
            "Epoch 31 - Average Training Loss: 0.8740198845863343\n",
            "Epoch 32 - Average Training Loss: 0.8652249979972839\n",
            "Epoch 33 - Average Training Loss: 0.8658085389137268\n",
            "Epoch 34 - Average Training Loss: 0.8530335974693298\n",
            "Epoch 35 - Average Training Loss: 0.8494880623817443\n",
            "Epoch 36 - Average Training Loss: 0.8421263251304626\n",
            "Epoch 37 - Average Training Loss: 0.8379078235626221\n",
            "Epoch 38 - Average Training Loss: 0.8312466421127319\n",
            "Epoch 39 - Average Training Loss: 0.8243451533317566\n",
            "Epoch 40 - Average Training Loss: 0.8149953255653382\n",
            "Epoch 41 - Average Training Loss: 0.8249522614479065\n",
            "Epoch 42 - Average Training Loss: 0.8181803526878357\n",
            "Epoch 43 - Average Training Loss: 0.8125510716438293\n",
            "Epoch 44 - Average Training Loss: 0.8082856645584107\n",
            "Epoch 45 - Average Training Loss: 0.8121509056091308\n",
            "Epoch 46 - Average Training Loss: 0.796357807636261\n",
            "Epoch 47 - Average Training Loss: 0.7922066555023194\n",
            "Epoch 48 - Average Training Loss: 0.7973098697662353\n",
            "Epoch 49 - Average Training Loss: 0.7917418732643128\n",
            "Epoch 50 - Average Training Loss: 0.7781068959236145\n",
            "Epoch 51 - Average Training Loss: 0.7863055992126465\n",
            "Epoch 52 - Average Training Loss: 0.7779808459281922\n",
            "Epoch 53 - Average Training Loss: 0.777585337638855\n",
            "Epoch 54 - Average Training Loss: 0.773740469455719\n",
            "Epoch 55 - Average Training Loss: 0.7736914286613464\n",
            "Epoch 56 - Average Training Loss: 0.7725204877853393\n",
            "Epoch 57 - Average Training Loss: 0.7672179050445557\n",
            "Epoch 58 - Average Training Loss: 0.7716900599002838\n",
            "Epoch 59 - Average Training Loss: 0.7606915595531464\n",
            "Epoch 60 - Average Training Loss: 0.7561909122467041\n",
            "Epoch 61 - Average Training Loss: 0.7584508876800538\n",
            "Epoch 62 - Average Training Loss: 0.7543668413162231\n",
            "Epoch 63 - Average Training Loss: 0.7512437453269959\n",
            "Epoch 64 - Average Training Loss: 0.7536898636817932\n",
            "Epoch 65 - Average Training Loss: 0.7412331609725952\n",
            "Epoch 66 - Average Training Loss: 0.7534022545814514\n",
            "Epoch 67 - Average Training Loss: 0.7462658247947693\n",
            "Epoch 68 - Average Training Loss: 0.7466213240623474\n",
            "Epoch 69 - Average Training Loss: 0.7446699066162109\n",
            "Epoch 70 - Average Training Loss: 0.7372461333274841\n",
            "Epoch 71 - Average Training Loss: 0.7352082662582398\n",
            "Epoch 72 - Average Training Loss: 0.7377244877815247\n",
            "Epoch 73 - Average Training Loss: 0.7389122920036316\n",
            "Epoch 74 - Average Training Loss: 0.7335008401870727\n",
            "Epoch 75 - Average Training Loss: 0.7314979193210602\n",
            "Epoch 76 - Average Training Loss: 0.7339500811100006\n",
            "Epoch 77 - Average Training Loss: 0.7323645725250244\n",
            "Epoch 78 - Average Training Loss: 0.7267465972900391\n",
            "Epoch 79 - Average Training Loss: 0.7262613778114319\n",
            "Epoch 80 - Average Training Loss: 0.7283495426177978\n",
            "Epoch 81 - Average Training Loss: 0.723813250541687\n",
            "Epoch 82 - Average Training Loss: 0.7192477478981018\n",
            "Epoch 83 - Average Training Loss: 0.7158057084083557\n",
            "Epoch 84 - Average Training Loss: 0.7183963489532471\n",
            "Epoch 85 - Average Training Loss: 0.7173281569480896\n",
            "Epoch 86 - Average Training Loss: 0.7120896077156067\n",
            "Epoch 87 - Average Training Loss: 0.7164925427436829\n",
            "Epoch 88 - Average Training Loss: 0.7126874213218689\n",
            "Epoch 89 - Average Training Loss: 0.7075672390460968\n",
            "Epoch 90 - Average Training Loss: 0.7112469282150269\n",
            "Epoch 91 - Average Training Loss: 0.7053760457038879\n",
            "Epoch 92 - Average Training Loss: 0.7019040198326111\n",
            "Epoch 93 - Average Training Loss: 0.7057052307128906\n",
            "Epoch 94 - Average Training Loss: 0.7119404039382935\n",
            "Epoch 95 - Average Training Loss: 0.7048192954063416\n",
            "Epoch 96 - Average Training Loss: 0.7004282336235046\n",
            "Epoch 97 - Average Training Loss: 0.7037485666275024\n",
            "Epoch 98 - Average Training Loss: 0.6952936744689941\n",
            "Epoch 99 - Average Training Loss: 0.6945438888072968\n",
            "Epoch 100 - Average Training Loss: 0.6912792181968689\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    average_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1} - Average Training Loss: {average_train_loss}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eWfOVcctvMf"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gKsGgw6Xt1lx"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "val_predictions = []\n",
        "val_true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        val_predictions.extend(logits.argmax(dim=1).tolist())\n",
        "        val_true_labels.extend(labels.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ90OvNrt5e3"
      },
      "source": [
        "##Classification Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QhEiTppat_uZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28bd635-7212-444b-ddc9-2cae7d1e6623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.094\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "          Allergy / Immunology       0.00      0.00      0.00         1\n",
            "                    Bariatrics       1.00      0.50      0.67         2\n",
            "    Cardiovascular / Pulmonary       0.00      0.00      0.00         3\n",
            "                     Neurology       0.13      0.16      0.15        69\n",
            "                     Dentistry       0.00      0.00      0.00         1\n",
            "                       Urology       0.06      0.06      0.06       107\n",
            "              General Medicine       0.00      0.00      0.00         4\n",
            "                       Surgery       0.14      0.12      0.13         8\n",
            "             Speech - Language       0.00      0.00      0.00         3\n",
            " SOAP / Chart / Progress Notes       0.00      0.00      0.00         1\n",
            "                Sleep Medicine       0.08      0.10      0.09        21\n",
            "                  Rheumatology       0.24      0.20      0.22        25\n",
            "                     Radiology       0.06      0.06      0.06        17\n",
            "       Psychiatry / Psychology       0.00      0.00      0.00         3\n",
            "                      Podiatry       0.12      0.14      0.13        42\n",
            "     Physical Medicine - Rehab       0.10      0.10      0.10        50\n",
            "         Pediatrics - Neonatal       0.04      0.07      0.05        15\n",
            "               Pain Management       0.00      0.00      0.00         2\n",
            "                    Orthopedic       0.00      0.00      0.00         1\n",
            "                 Ophthalmology       0.00      0.00      0.00         1\n",
            "                  Office Notes       0.00      0.00      0.00         1\n",
            "       Obstetrics / Gynecology       0.00      0.00      0.00        15\n",
            "                  Neurosurgery       0.07      0.07      0.07        44\n",
            "                    Nephrology       0.05      0.06      0.05        18\n",
            "                       Letters       0.07      0.06      0.06        35\n",
            "      Lab Medicine - Pathology       0.00      0.00      0.00        11\n",
            "        IME-QME-Work Comp etc.       0.14      0.17      0.15        18\n",
            "     Hospice - Palliative Care       0.08      0.09      0.09        68\n",
            "         Hematology - Oncology       0.50      0.67      0.57         9\n",
            "              Gastroenterology       0.00      0.00      0.00        15\n",
            "          ENT - Otolaryngology       0.20      0.14      0.17         7\n",
            "                 Endocrinology       0.00      0.00      0.00         5\n",
            "        Emergency Room Reports       0.07      0.14      0.10         7\n",
            "             Discharge Summary       0.15      0.10      0.12        68\n",
            "          Diets and Nutritions       0.00      0.00      0.00         6\n",
            "                   Dermatology       0.00      0.00      0.00        27\n",
            "    Cosmetic / Plastic Surgery       0.00      0.00      0.00         2\n",
            "    Consult - History and Phy.       0.00      0.00      0.00         0\n",
            "                  Chiropractic       0.12      0.10      0.11       231\n",
            "                       Autopsy       0.03      0.03      0.03        37\n",
            "\n",
            "                      accuracy                           0.09      1000\n",
            "                     macro avg       0.09      0.08      0.08      1000\n",
            "                  weighted avg       0.10      0.09      0.09      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(val_true_labels, val_predictions)\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n",
        "\n",
        "class_names = df['medical_specialty'].unique()\n",
        "class_names = [str(class_name) for class_name in class_names]\n",
        "report = classification_report(val_true_labels, val_predictions, target_names=class_names)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDJGPJluuB6a"
      },
      "source": [
        "## Saving the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "FGsgaa4puCdf"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"medical_specialty_classifier\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}